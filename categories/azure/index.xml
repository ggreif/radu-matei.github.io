<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Radu Matei - Developer Evangelist</title>
    <link>https://radu-matei.com/categories/azure/index.xml</link>
    <description>Recent content on Radu Matei - Developer Evangelist</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="https://radu-matei.com/categories/azure/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Best of Both worlds: Azure App Service and Kubernetes</title>
      <link>https://radu-matei.com/blog/k8s-appsvc/</link>
      <pubDate>Tue, 17 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://radu-matei.com/blog/k8s-appsvc/</guid>
      <description>

&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of Contents&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#prerequisites&#34;&gt;Prerequisites&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#why-not-just-expose-services-publicly&#34;&gt;Why not just expose services publicly?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deploy-kubernetes-services-with-a-private-ip&#34;&gt;Deploy Kubernetes services with a private IP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-networking-settings&#34;&gt;The networking settings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#testing-the-integration&#34;&gt;Testing the integration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#next-steps&#34;&gt;Next Steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feedback&#34;&gt;Feedback&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In this article we will explore how to integrate Azure App Service and Kubernetes within the same Azure Virtual Network and consume Kubernetes services from an Azure App Service app without exposing them on the public Internet.&lt;/p&gt;

&lt;p&gt;There will be lots of situations when we want to use both the simplicity and features of a PaaS service (such as autoscaling, easy SSL, or any other cool feature) for a component and the flexibility of Kubernetes for others - in this article we will see how to achieve this without exposing services on the Internet.&lt;/p&gt;

&lt;p&gt;We will start from a just-deployed Kubernetes cluster, will see how to expose services internally in an Azure VNet using an Azure Internal Load Balancer, then we will see how to connect an Azure App Service to that VNet, consuming services on the cluster from our App Service without exposing them on the public Internet.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that in order to deploy a Kubernetes cluster on Azure you can either &lt;a href=&#34;https://radu-matei.com/blog/k8s18-azure/&#34;&gt;use &lt;code&gt;acs-engine&lt;/code&gt; (a tool that deploys custom clusters on Azure) - here&amp;rsquo;s how to deploy Kubernetes 1.8 on Azure using &lt;code&gt;acs-engine&lt;/code&gt;&lt;/a&gt; or &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/container-service/kubernetes/container-service-kubernetes-walkthrough&#34;&gt;use the &lt;code&gt;az&lt;/code&gt; command line - here&amp;rsquo;s the official documentation.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;

&lt;p&gt;This tutorial assumes you have a valid Azure subscription that you can use to deploy resorces. If you don&amp;rsquo;t have an Azure subscription you can &lt;a href=&#34;https://azure.microsoft.com/en-us/free/?v=17.39a&#34;&gt;create a free account and get $200 for 12 months&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This tutorial uses a 4-node Kubernetes cluster (1 master + 3 agents) deployed on Azure. The machines are 4 D2_V2 VMs with Linux that will cost approximately $13 - $14 / day, but you can change the type of the VM to be D1_V2, and the cost will go down to $6 / day.&lt;/p&gt;

&lt;p&gt;Besides the Kubernetes cluster, this article will also use an Azure App Service, with at least the Standard pricing tier (in order to support the VNet gateway feature, but more on this later), which in development starts at around  $1.5 / day.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/pricing.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the pricing will vary slightly based on the location where you deploy the VMs.&lt;/p&gt;

&lt;p&gt;Cost estimation created using the &lt;a href=&#34;https://azure.microsoft.com/en-us/pricing/calculator/&#34;&gt;Azure Pricing Calculator&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This tutorial will also use an Azure VNet gateway that based on the throughput needed can go from less than $1/day (for 100 Mbps) to around $30/day (for 1.25 Gpbs).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Here you can &lt;a href=&#34;https://azure.microsoft.com/en-us/pricing/details/vpn-gateway/&#34;&gt;find out more about the Azure VPN Gateway&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;why-not-just-expose-services-publicly&#34;&gt;Why not just expose services publicly?&lt;/h2&gt;

&lt;p&gt;The alternative to this entire article is simply exposing public services from Kubernetes with a public IP address and just use that public IP address from your App Service application.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s explore some of the reasons you might not want to do this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;security risks and implications - it means that your services are exposed publicly and you need to deal with the risks associated&lt;/li&gt;
&lt;li&gt;latency - you will go over the Internet to access your service, meaning you will get higher latency&lt;/li&gt;
&lt;li&gt;networking cost - public IPs, outbound traffic (data going out of a datacenter) cost money&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Networking pricing is a complex topic in any cloud provider and I am by no means expert in Azure Networking - you can read more about Azure Networking &lt;a href=&#34;https://azure.microsoft.com/en-us/pricing/details/virtual-network/&#34;&gt;pricing for virtual networks&lt;/a&gt;, for &lt;a href=&#34;https://azure.microsoft.com/en-us/pricing/details/vpn-gateway/&#34;&gt;VPN gateways&lt;/a&gt; and &lt;a href=&#34;https://azure.microsoft.com/en-us/pricing/details/bandwidth/&#34;&gt;bandwidth&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;deploy-kubernetes-services-with-a-private-ip&#34;&gt;Deploy Kubernetes services with a private IP&lt;/h2&gt;

&lt;p&gt;When you deploy Kubernetes in Azure, all resources (network interfaces of VMs, load balancers) are deployed in a virtual network, and each VM gets a private IP inside that VNet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/k8s-vnet.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In the picture above you can see the internal IP of each node and subnet they belong to.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now when you deploy an internal service on the cluster (that is without exposing it through a load balancer or through a node port), Kubernetes will assign your service a &lt;em&gt;cluster IP&lt;/em&gt;. This IP (together with the hostname associated with it: &lt;code&gt;&amp;lt;service&amp;gt;.&amp;lt;namespace&amp;gt;&lt;/code&gt;) is only accessible to other services in the cluster - this means that another service in the same VNet, for example a VM that is not part of the cluster will &lt;em&gt;not be able to access that service.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;However, in order to access Kubernetes services from within that virtual network, you need to specify an internal load balancer using an annotation when you create the service.
That being said, let&amp;rsquo;s see how a Kubernetes service that is internally exposed in the virtual network looks like:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/4802dc126af06829b1904c49e4b97d57.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The only notable thing is the annotation part of the service: &lt;code&gt;service.beta.kubernetes.io/azure-load-balancer-internal: &amp;quot;true&amp;quot;&lt;/code&gt; - this tells Kubernetes to ask Azure for an internal load balancer. So after we deploy this, we will see a private IP of this service, as well as a newly created internal load balancer in Azure:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/internal-lb.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now if we take a look at the Kubernetes services:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/kubectl-service.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And the IP address of the internal load balancer:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/private-ip.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-networking-settings&#34;&gt;The networking settings&lt;/h2&gt;

&lt;p&gt;So we now have a Kubernetes service accessible from within our virtual network. We now need to integrate an App Service instance in that virtual network to consume the API we deployed.&lt;/p&gt;

&lt;p&gt;By default, when deploying an App Service application, it is not connected to a virtual network. Now it&amp;rsquo;s worth mentioning that App Service comes in two forms:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The multi-tenant systems that support the full range of pricing plans - this is the most common and most used version&lt;/li&gt;
&lt;li&gt;The &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/app-service/environment/intro&#34;&gt;App Service Environment (ASE)&lt;/a&gt; premium feature, which deploys into your VNet.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this article we will focus on integrating a regular App Service with an Azure Virtual Network, and it is also worth mentioning some features, restrictions and limitations:&lt;/p&gt;

&lt;p&gt;The VNet Integration feature:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;requires a Standard, Premium, or Isolated pricing plan&lt;/li&gt;
&lt;li&gt;works with Classic or Resource Manager VNet&lt;/li&gt;
&lt;li&gt;supports TCP and UDP&lt;/li&gt;
&lt;li&gt;works with Web, Mobile, and API apps&lt;/li&gt;
&lt;li&gt;enables an app to connect to only 1 VNet at a time&lt;/li&gt;
&lt;li&gt;enables up to five VNets to be integrated with in an App Service Plan&lt;/li&gt;
&lt;li&gt;allows the same VNet to be used by multiple apps in an App Service Plan&lt;/li&gt;
&lt;li&gt;supports a 99.9% SLA due to the SLA on the VNet Gateway&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are some things that VNet Integration does not support including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;mounting a drive&lt;/li&gt;
&lt;li&gt;AD integration&lt;/li&gt;
&lt;li&gt;NetBios&lt;/li&gt;
&lt;li&gt;private site access&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;The previous information and more details can be found on &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/app-service/web-sites-integrate-with-vnet&#34;&gt;the official App Service Documentation here&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Basically, there will be a point-to-site VPN to the VNet where Kuberentes is deployed, the point being our App Service instance.
Now in order to create this, we first need to &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/app-service/web-sites-integrate-with-vnet#enabling-vnet-integration&#34;&gt;enable the VNet integration, as described in this article&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you go to the Networking tab of your App Service and try to enable the VNet integration for your Kubernetes VNet, you will see the following message:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/no-gateway.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This means there is no &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpngateways&#34;&gt;VPN Gateway&lt;/a&gt; configured in that private network.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A virtual network gateway is composed of two or more virtual machines that are deployed to a specific subnet called the GatewaySubnet. The VMs that are located in the GatewaySubnet are created when you create the virtual network gateway. Virtual network gateway VMs are configured to contain routing tables and gateway services specific to the gateway. You can&amp;rsquo;t directly configure the VMs that are part of the virtual network gateway and you should never deploy additional resources to the GatewaySubnet.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/azure/vpn-gateway/vpn-gateway-about-vpngateways&#34;&gt;More on VPN Gateways here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So you need to create a VPN Gateway on that virtual network (keeping in mind to configure it based on your needs), and also keeping in mind that it could take up to half an hour to configure it:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/create-gateway.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;30 minutes later we have a Virtual Network Gateway deployed in the same VNet as the Kubernetes cluster. Now if we go back and try to setup the App Service, we see that we haven&amp;rsquo;t configured point-to-site VPN for this network:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/no-pts.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;From the gateway menu in the portal configure point-to-site (with your own value for the client address pool). Note that you don&amp;rsquo;t need to setup certificates, these will be created automatically when you connect the App Service with the gateway.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/pts.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After you configure point-to-site in the network, you can go back to the App Service and configure the VNet access:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/setup.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;testing-the-integration&#34;&gt;Testing the integration&lt;/h2&gt;

&lt;p&gt;Now to the moment of truth: I created a very simple .NET Core app (it can be Node, PHP, Java) that makes requests to a &lt;code&gt;PrivateAddress&lt;/code&gt; that you can configure in the App Settings in Azure Portal. You can &lt;a href=&#34;https://github.com/radu-matei/app-svc-vnet&#34;&gt;find the app on GitHub&lt;/a&gt;, but all it does is make an HTTP request and return the response.&lt;/p&gt;

&lt;p&gt;Now if you fork the repo above and do a &lt;a href=&#34;https://blogs.msdn.microsoft.com/benjaminperkins/2017/05/10/deploy-github-source-code-repositories-to-an-azure-app-service/&#34;&gt;GitHub deployment directly to Azure App Service&lt;/a&gt;, then create an App Setting for &lt;code&gt;PrivateAddress&lt;/code&gt; with the private IP of your service in the virtual network:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/private-address.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Then, when you access &lt;code&gt;/api/privatestuff&lt;/code&gt; on your public web app, you can see that it actually makes requests inside your virtual network:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/access.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here you can see which pod actually responded to the request, and if you refresh, you can see the requests are load balanced.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-appsvc/pods.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;current-known-limitations&#34;&gt;Current known limitations&lt;/h2&gt;

&lt;p&gt;Right now you cannot use this article with a Web App on Containers or App Service on Linux, as the VNet integration does not currently support them.&lt;/p&gt;

&lt;p&gt;Also, you currently cannot have &lt;a href=&#34;https://feedback.azure.com/forums/217313-networking/suggestions/16825357-add-dns-name-label-to-private-ips&#34;&gt;DNS name for the internal IP of the load balancer. This is known feature request on Azure Feedback, and according to the Azure Networking team, it represents a key item on the roadmap&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Now you have successfully deployed an application on App Service that uses private APIs from within a non-Internet routable network. You get the best of both worlds: the ease of deployment, autoscaling, SSL and other fun features of App Service, with the flexibility of Kubernetes, all in the same application.&lt;/p&gt;

&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;A next step would be creating deployment pipelines for both App Service and the Kubenetes apps - &lt;a href=&#34;https://github.com/azure-devops/movie-db-java-on-azure&#34;&gt;here is an example of a pipeline using Jenkins&lt;/a&gt; for a web app on App Service with the backend in Kubernetes.&lt;/p&gt;

&lt;h2 id=&#34;feedback&#34;&gt;Feedback&lt;/h2&gt;

&lt;p&gt;If you have a better aproach at any of the concepts presented in this article, or have any questions, please use the comments below.&lt;/p&gt;

&lt;p&gt;As always, thanks for reading, and any feedback is highly appreciated :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Get started with Helm and Draft for Kubernetes</title>
      <link>https://radu-matei.com/blog/k8s-helm-draft-azure/</link>
      <pubDate>Sat, 07 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://radu-matei.com/blog/k8s-helm-draft-azure/</guid>
      <description>

&lt;h1 id=&#34;table-of-contents&#34;&gt;Table of contents&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-kubectl-helm-and-draft&#34;&gt;Using kubectl, helm and draft&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#configure-helm&#34;&gt;Configure Helm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#configure-draft&#34;&gt;Configure Draft&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-an-application&#34;&gt;Creating an application&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#investigating-what-actually-happens&#34;&gt;Investigating what actually happens&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exiting-the-container&#34;&gt;Exiting the container&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#feedback&#34;&gt;Feedback&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://radu-matei.com/blog/k8s18-azure/&#34;&gt;In the previous tutorial&lt;/a&gt; I used Azure to provision the infrastructure required to run a Kubernetes cluster. If you don&amp;rsquo;t have an Azure subscription you can &lt;a href=&#34;https://azure.microsoft.com/en-us/free/?v=17.39a&#34;&gt;create a free account and get $200 for 12 months&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I deployed 4 D2_V2 VMs (1 master + 3 agents) with Linux and will cost approximately $13 - $14 / day, but you can change the type of the VM to be D1_V2 in the cluster definition, and the cost will go down to $6 / day.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the pricing will vary slightly based on the location where you deploy the VMs.&lt;/p&gt;

&lt;p&gt;Cost estimation created using the &lt;a href=&#34;https://azure.microsoft.com/en-us/pricing/calculator/&#34;&gt;Azure Pricing Calculator&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s18-azure/pricing.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://radu-matei.com/blog/k8s18-azure/&#34;&gt;In the previous post we saw how to deploy a Kubernetes 1.8 cluster on Azure using &lt;code&gt;acs-engine&lt;/code&gt; and the Azure Cloud Shell&lt;/a&gt;. Now we will use that cluster to get started with Helm and Draft to simplify our development process.&lt;/p&gt;

&lt;p&gt;In the next post we will see how to integrate Jenkins with Azure Contaier Instances in this process, so stay tuned :)&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you don&amp;rsquo;t have your &lt;code&gt;kubeconfig&lt;/code&gt; and SSH keys to your &lt;a href=&#34;https://radu-matei.com/blog/k8s18-azure/&#34;&gt;cluster and you deployed using the previous article, you might want to download the certificates and config files so you can access the cluster from outside the Azure Cloud Shell, as instructed in the previous article&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;using-kubectl-helm-and-draft&#34;&gt;Using kubectl, helm and draft&lt;/h1&gt;

&lt;p&gt;Normally at this point you would manually download and install the latest version for &lt;code&gt;kubectl&lt;/code&gt;, &lt;code&gt;helm&lt;/code&gt; and &lt;code&gt;draft&lt;/code&gt;. Luckily, you can use the Dockerfile below to create yourself an image that already has those installed.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/dba91743ae04784076f31485a5a521a2.js&#34;&gt;&lt;/script&gt;

&lt;blockquote&gt;
&lt;p&gt;You can find &lt;a href=&#34;https://github.com/radu-matei/kubectl-helm-draft&#34;&gt;the repository on GitHub here&lt;/a&gt; and &lt;a href=&#34;https://hub.docker.com/r/radumatei/kubectl-helm-draft/&#34;&gt;the image on Docker Hub&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Please note that at the time of writing this article, the lastest versions are: &lt;code&gt;v1.8.0&lt;/code&gt; for &lt;code&gt;kubectl&lt;/code&gt;, &lt;code&gt;v2.6.2&lt;/code&gt; for &lt;code&gt;helm&lt;/code&gt; and &lt;code&gt;v0.7.0&lt;/code&gt; for &lt;code&gt;draft&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;When a new version is available, simply change the environment variable in the Dockerfile and build again.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;One reason for this is that I regularly work with multiple clusters, and all of these commands create their config in the home directory. Not once it happened that I overwrote the config (for &lt;code&gt;kubectl&lt;/code&gt;, &lt;code&gt;helm&lt;/code&gt; or &lt;code&gt;draft&lt;/code&gt;). I really think this is cleaner approach - you have a folder for your cluster with all its config there. Another cluster, simply another folder.&lt;/p&gt;

&lt;p&gt;Then, you use the config from within a container.&lt;/p&gt;

&lt;p&gt;The image simply installs &lt;code&gt;kubectl&lt;/code&gt;, &lt;code&gt;helm&lt;/code&gt; and &lt;code&gt;draft&lt;/code&gt; and exposes a port inside the container (so we can easily &lt;code&gt;kubectl proxy&lt;/code&gt; a bit later).&lt;/p&gt;

&lt;p&gt;Now all you need to do is run a conainer based on the image you just built, and mount the cluster access certificates folder so we can point &lt;code&gt;kubectl&lt;/code&gt; at.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/c3a8619208fdaab90ccb1a82785e1731.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/initial-run.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you don&amp;rsquo;t know where those certificates came from, &lt;a href=&#34;https://radu-matei.com/blog/k8s18-azure/&#34;&gt;check out this article&lt;/a&gt; and modify the path to match your own.&lt;/p&gt;

&lt;p&gt;I also mounted a local directory so I can later create an application from outside the container and exposed port 8080 (you can choose another one) to access the dashboard.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Of course, neither &lt;code&gt;helm&lt;/code&gt;, nor &lt;code&gt;draft&lt;/code&gt; will be able to connect to the cluster, as their server-side components (&lt;code&gt;tiller&lt;/code&gt; and &lt;code&gt;draftd&lt;/code&gt;) are not configured yet.&lt;/p&gt;

&lt;p&gt;Now simply point &lt;code&gt;kubectl&lt;/code&gt; to your &lt;code&gt;kubeconfig&lt;/code&gt; file (in my case in the &lt;code&gt;_output&lt;/code&gt; folder from &lt;code&gt;acs-engine&lt;/code&gt;, but can be from anywhere) and you have yourself a container with the latest tools for Kubernetes, connected to a cluster running the latest version of Kubernetes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/export-config.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;configure-helm&#34;&gt;Configure Helm&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Helm is a tool that streamlines installing and managing Kubernetes applications. Think of it like apt/yum/homebrew for Kubernetes.&lt;/p&gt;

&lt;p&gt;Helm has two parts: a client (helm) and a server (tiller)&lt;/p&gt;

&lt;p&gt;Tiller runs inside of your Kubernetes cluster, and manages releases (installations) of your charts.&lt;/p&gt;

&lt;p&gt;Helm runs on your laptop, CI/CD, or wherever you want it to run.&lt;/p&gt;

&lt;p&gt;Charts are Helm packages that contain at least two things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;A description of the package (Chart.yaml)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;One or more templates, which contain Kubernetes manifest files&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Charts can be stored on disk, or fetched from remote chart repositories (like Debian or RedHat packages)&lt;/p&gt;

&lt;p&gt;More on &lt;a href=&#34;https://github.com/kubernetes/helm&#34;&gt;the GitHub repo for Helm&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We now need to initialize &lt;code&gt;helm&lt;/code&gt;. Since we are in a container, once we exit all config files written by &lt;code&gt;helm&lt;/code&gt; and &lt;code&gt;draft&lt;/code&gt; will be lost. That&amp;rsquo;s why we have the &lt;code&gt;cluster&lt;/code&gt; directory, which is mounted from the host.&lt;/p&gt;

&lt;p&gt;We will now need to point &lt;code&gt;helm&lt;/code&gt; to write its config in &lt;code&gt;/cluster&lt;/code&gt; and run &lt;code&gt;helm init&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;export HELM_HOME=/cluster/&lt;/code&gt; and &lt;code&gt;helm init&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/helm-init.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Please note that the default server version of &lt;code&gt;tiller&lt;/code&gt; (the &lt;code&gt;helm&lt;/code&gt; server-side component) is at version &lt;code&gt;v2.6.1&lt;/code&gt;. You can easily upgrade it using &lt;code&gt;helm init --upgrade&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/helm-upgrade.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We now have configured &lt;code&gt;helm&lt;/code&gt;:
&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/helm-ls-search.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;configure-draft&#34;&gt;Configure Draft&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Draft makes it easy to build applications that run on Kubernetes. Draft targets the &amp;ldquo;inner loop&amp;rdquo; of a developer&amp;rsquo;s workflow: as they hack on code, but before code is committed to version control.&lt;/p&gt;

&lt;p&gt;Using Draft is as simple as:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;draft create&lt;/code&gt; to containerize your application based on Draft packs&lt;/p&gt;

&lt;p&gt;&lt;code&gt;draft up&lt;/code&gt; to deploy your application to a Kubernetes dev sandbox, accessible via a public URL&lt;/p&gt;

&lt;p&gt;Use a local editor to modify the application, with changes deployed to Kubernetes in seconds&lt;/p&gt;

&lt;p&gt;Once the developer is happy with changes made via Draft, they commit and push to version control, after which a continuous integration (CI) system takes over. Draft builds upon Kubernetes Helm and the Kubernetes Chart format, making it easy to construct CI pipelines from Draft-enabled applications.&lt;/p&gt;

&lt;p&gt;More on &lt;a href=&#34;https://github.com/azure/draft&#34;&gt;the GitHub repo for Draft&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now we are going to use &lt;a href=&#34;https://github.com/Azure/draft/blob/master/docs/ingress.md&#34;&gt;a very cool feature of Draft called ingress&lt;/a&gt;. Basically, this will allow us to use a base domain - &lt;code&gt;*.draft.yourdomain.com&lt;/code&gt; to expose your apps while testing. Of course, you will need to own a domain and to be able to create a wildcard &lt;code&gt;A Record&lt;/code&gt; pointing back to an nginx controller in your cluster.&lt;/p&gt;

&lt;p&gt;You will use &lt;code&gt;helm&lt;/code&gt; to deploy an nginx ingress controller with a public IP address (if you are on Azure or GKE this will be done automatically for you after a couple of minutes):&lt;/p&gt;

&lt;p&gt;&lt;code&gt;helm install stable/nginx-ingress --namespace=kube-system --name=nginx-ingress&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/nginx.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the nginx ingress controller also deploys a default backend - this will be served as a default backend (pretty clear name there).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now depending on where you manage your domain, you need to go and create the &lt;code&gt;A Record&lt;/code&gt; with a wildcard pointing back to the IP address of your ingress controller.&lt;/p&gt;

&lt;p&gt;In my case I manage my domain using CloudFlare, so the steps are pretty clear and straightforward:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/cloudflare.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We will also point &lt;code&gt;draft&lt;/code&gt; to write its config in &lt;code&gt;/cluster&lt;/code&gt;: &lt;code&gt;export DRAFT_HOME=/cluster&lt;/code&gt; and initialize &lt;code&gt;draft&lt;/code&gt;, specifying it to also configure the ingress controller:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;draft init --ingress-enabled&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This will prompt you to enter your container registry credentials and the top level domain record you created.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that if you are using Docker Hub, the URL is: docker.io/username&lt;/p&gt;

&lt;p&gt;Note that you need to specify the top level domain (without the wildcard, see image below)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/draft-init.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now if we inspect our cluster we can see the &lt;code&gt;draftd&lt;/code&gt; server, &lt;code&gt;tiller&lt;/code&gt; and the ingress controller.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/inspect.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Azure/draft/blob/master/docs/ingress.md#i-dont-manage-a-domain&#34;&gt;If you don&amp;rsquo;t manage a domain, please see the instructions here&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;creating-an-application&#34;&gt;Creating an application&lt;/h1&gt;

&lt;p&gt;Remember earlier that we also mounted a local directory where we will write our application. This was to allow us to easily use VS Code to develop the application.&lt;/p&gt;

&lt;p&gt;Now to the part where we actually create an application.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can &lt;a href=&#34;https://github.com/Azure/draft/blob/master/docs/getting-started.md&#34;&gt;find a getting started guide at the GitHub repo for Draft&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/Azure/draft/blob/master/docs/packs.md&#34;&gt;Draft already has packs&lt;/a&gt; that can autodetect your application and deploy it to your cluster for you.&lt;/p&gt;

&lt;p&gt;The packs are basically &lt;code&gt;helm&lt;/code&gt; chart templates for &lt;a href=&#34;https://github.com/Azure/draft/tree/master/packs&#34;&gt;various programming languages and frameworks&lt;/a&gt;, and you can easily write your own pack.&lt;/p&gt;

&lt;p&gt;This is the application we will use, a very simple Go web app:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/7de20b06733ffcc187153cdfa8abf087.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/simple-go.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We will create a new app using &lt;code&gt;draft&lt;/code&gt; by executing &lt;code&gt;draft create --app &amp;lt;name-for-app&amp;gt;&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/draft-create.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This command will detect the application language (that 6 digit certainty&amp;hellip; :D) and create some new files for us: a Dockerfile, a &lt;code&gt;draft.toml&lt;/code&gt; file and a Helm chart.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/new-files.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Taking a look at &lt;code&gt;draft.toml&lt;/code&gt;, we can see that it will deploy a new app called &lt;code&gt;simple-go&lt;/code&gt; (that&amp;rsquo;s how I named it, if you omit the name you will get a randomly generated name) on the &lt;code&gt;default&lt;/code&gt; namespace.&lt;/p&gt;

&lt;p&gt;If you change the &lt;code&gt;watch&lt;/code&gt; property to &lt;code&gt;true&lt;/code&gt;, it will also look for changes on your local filesystem and redeploy the app on every change:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[environments]
  [environments.development]
    name = &amp;quot;simple-go&amp;quot;
    namespace = &amp;quot;default&amp;quot;
    wait = false
    watch = true
    watch_delay = 2

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Executing &lt;code&gt;draft up&lt;/code&gt; will automatically build the image and push it to the image repository.&lt;/p&gt;

&lt;p&gt;Note that all the work is done inside a pod in your cluster! There is no &lt;code&gt;docker build&lt;/code&gt; or &lt;code&gt;docker push&lt;/code&gt; step executed locally.&lt;/p&gt;

&lt;p&gt;Then there is the release step, which will install the Helm chart of your application on the cluster, also configuring the public endpoint of your application as: http:// draft-app-name.A-Record.yourdomain.com.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/build.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/app.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In my case, the public endpoint of my application will be: &lt;a href=&#34;http://simple-go.draft.k8s.radu-matei.com&#34;&gt;http://simple-go.draft.k8s.radu-matei.com&lt;/a&gt; :&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/public-app.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that for any update of your application (that is you modifying the app locally and saving it) while the &lt;code&gt;draft up&lt;/code&gt; process is running, you will get the updated version of your application deployed automatically.&lt;/p&gt;

&lt;h1 id=&#34;investigating-what-actually-happens&#34;&gt;Investigating what actually happens&lt;/h1&gt;

&lt;p&gt;Remember that you also exposed port 8080 from the container? Now it&amp;rsquo;s time to start the proxy that will allow us to browse the Kubernetes dashboard locally:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl proxy --port 8080 --address 0.0.0.0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Then, if you also exposed port 8080 on your host can access: &lt;a href=&#34;http://localhost:8080/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy/#!/node?namespace=_all&#34;&gt;http://localhost:8080/api/v1/namespaces/kube-system/services/kubernetes-dashboard/proxy/#!/node?namespace=_all&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;If you go to all your pods, you will see a pod called &lt;code&gt;draftd-&amp;lt;some-random-id&amp;gt;&lt;/code&gt;:
&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/draftd-pod.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;If you go to its logs, you will see the image building and pushing process:
&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/draftd-logs.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Among other logs, you can see that it pushd the image to the container image repository we specified when initially setting up &lt;code&gt;draft&lt;/code&gt;, &lt;code&gt;draftaccount&lt;/code&gt;, with the name we specified for the app. Let&amp;rsquo;s see that:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s-helm-draft-azure/docker-hub.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now you can update the app locally (save the source code) and the app will be automatically updated on your cluster.
You don&amp;rsquo;t need to have Go (or whatever language you use for developement) locally, not even Docker. Using Draft you don&amp;rsquo;t need to understand how to write a Dockerfile, or a Helm chart - you simply want your app in the cluster.&lt;/p&gt;

&lt;h1 id=&#34;exiting-the-container&#34;&gt;Exiting the container&lt;/h1&gt;

&lt;p&gt;When you are done working, simply exit the container - no global config was written, no context switching is necessary to change between different clusters - you simply have a directory with all config for your cluster - &lt;code&gt;kubeconfig&lt;/code&gt; and config for &lt;code&gt;helm&lt;/code&gt; and &lt;code&gt;draft&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The next time you need to work with this cluster, either start this same container, or start a new one with the same command as above and mount the folder with the config.&lt;/p&gt;

&lt;p&gt;Moreover, if you use multiple machines, you can keep the config folders in a file share (Azure Storage, Google Cloud Storage Bucket, S3) and start the container that has all the tools there. No more pasting SSH keys and cluster config files on Slack (guilty here&amp;hellip;)&lt;/p&gt;

&lt;p&gt;You can also use the same container with a different config folder for another cluster. That easy :)&lt;/p&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;We saw how to get started with Helm and Draft and tried a new approach at config management for multiple clusters using a config folder for each cluster.
We configured &lt;code&gt;helm&lt;/code&gt; and &lt;code&gt;draft&lt;/code&gt;, set up an ingress controller that used a domain we own, then deployed new apps to the cluster in seconds without writing Dockerfiles, Kubernetes deployment files or Helm charts.  We just worry about our app.&lt;/p&gt;

&lt;h1 id=&#34;feedback&#34;&gt;Feedback&lt;/h1&gt;

&lt;p&gt;If you have a better aproach at any of the concepts presented in this article, or have any questions, please use the comments below.
As always, thanks for reading, and any feedback is highly appreciated :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Kubernetes 1.8 on Azure</title>
      <link>https://radu-matei.com/blog/k8s18-azure/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://radu-matei.com/blog/k8s18-azure/</guid>
      <description>

&lt;h1 id=&#34;table-of-content&#34;&gt;Table of Content&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deploying-orchestrator-clusters-in-azure&#34;&gt;Deploying orchestrator clusters in Azure&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#getting-the-acs-engine-binary&#34;&gt;Getting the acs-engine binary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#deploy-the-cluster&#34;&gt;Deploy the cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion-feedback&#34;&gt;Conclusion and feedback&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h1&gt;

&lt;p&gt;This tutorial uses Azure to provision the infrastructure required to run a Kubernetes cluster. If you don&amp;rsquo;t have an Azure subscription you can &lt;a href=&#34;https://azure.microsoft.com/en-us/free/?v=17.39a&#34;&gt;create a free account and get $200 for 12 months&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This tutorial deploys 4 D2_V2 VMs (1 master + 3 agents) with Linux that will cost approximately $13 - $14 / day, but you can change the type of the VM to be D1_V2, and the cost will go down to $6 / day.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the pricing will vary slightly based on the location where you deploy the VMs.&lt;/p&gt;

&lt;p&gt;Cost estimation created using the &lt;a href=&#34;https://azure.microsoft.com/en-us/pricing/calculator/&#34;&gt;Azure Pricing Calculator&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s18-azure/pricing.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;On September 28th, Kubernetes hit version 1.8 with improved support for Role Based Access Control (RBAC), TLS certificate rotation and other cool features. &lt;a href=&#34;http://blog.kubernetes.io/2017/09/kubernetes-18-security-workloads-and.html&#34;&gt;You can read the full blog post that announces the release here&lt;/a&gt; and you can see &lt;a href=&#34;https://github.com/kubernetes/kubernetes/releases/tag/v1.8.0&#34;&gt;the release on GitHub&lt;/a&gt; and the &lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG.md#v180&#34;&gt;associated changelog with all new features&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this article we will explore how to deploy a Kubernetes cluster with version 1.8 on Azure.&lt;/p&gt;

&lt;p&gt;If you are familiar with deploying orchestrators in Azure, or you only want to see how to deploy Kubernetes 1.8, you can &lt;a href=&#34;#getting-the-acs-engine-binary&#34;&gt;skip the following section and go directly to where the action actually starts.&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;deploying-orchestrator-clusters-in-azure&#34;&gt;Deploying orchestrator clusters in Azure&lt;/h1&gt;

&lt;p&gt;There are a couple of ways to deploy an orchestrator cluster in Azure. First, there is Azure Container Service (that we used in the past to &lt;a href=&#34;https://radu-matei.com/blog/kubernetes-jenkins-azure/&#34;&gt;deploy a Kubernetes cluster&lt;/a&gt;). &lt;a href=&#34;https://azure.microsoft.com/en-us/services/container-service/&#34;&gt;Azure Container Service&lt;/a&gt; allows you to easily &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/container-service/&#34;&gt;deploy Kubernetes, Docker Swarm or DC/OS clusters from the Azure Portal or using the &lt;code&gt;az&lt;/code&gt; command line&lt;/a&gt;. This is the way to go if you don&amp;rsquo;t want to customize your cluster and you are ok with the default values that Azure provides for you.&lt;/p&gt;

&lt;p&gt;Then there is a tool called &lt;a href=&#34;https://github.com/azure/acs-engine&#34;&gt;&lt;code&gt;acs-engine&lt;/code&gt;&lt;/a&gt;. This is basically the &amp;ldquo;engine&amp;rdquo; that Azure Container Service uses to deploy your clusters, and we will use it to deploy a custom version of our Kubernetes cluster, in this case the new 1.8 version.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;acs-engine&lt;/code&gt; takes a &lt;a href=&#34;https://github.com/Azure/acs-engine/blob/master/docs/clusterdefinition.md&#34;&gt;cluster definition file&lt;/a&gt; where you can specify options for your cluster (like orchestrator to use - Kubernetes, Docker Swarm Mode, DC/OS and their specific versions, networking policies, master and agent profiles and others) and generates &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-authoring-templates&#34;&gt;ARM (Azure Resource Manager) templates&lt;/a&gt; that Azure uses to deploy all resources for your cluster (VMs for masters and agents with your orchestrator configured, load balancers, networking, storage adn other resources).&lt;/p&gt;

&lt;p&gt;Kubernetes 1.8 has just been released, and together with it came &lt;a href=&#34;https://github.com/Azure/acs-engine/releases&#34;&gt;v0.8.0 of &lt;code&gt;acs-engine&lt;/code&gt;&lt;/a&gt; with support for Kubernetes 1.8.&lt;/p&gt;

&lt;p&gt;You can follow this article on your local machine, inside a Docker container or using the Azure Cloud Shell, and all of these versions being very similar (basically you only change the OS version of the acs-engine binary).&lt;/p&gt;

&lt;h1 id=&#34;getting-the-acs-engine-binary&#34;&gt;Getting the acs-engine binary&lt;/h1&gt;

&lt;p&gt;In this step all you need to do is download the the binary associated with v0.8.0 of &lt;code&gt;acs-engine&lt;/code&gt; for your operating system. I will use the Azure Cloud Shell (which is Linux), but you can do the same thing for macOS (by getting the Darwin specific binaries) or for Windows.&lt;/p&gt;

&lt;p&gt;First you need to download the GitHub release archive for Linux:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;wget https://github.com/Azure/acs-engine/releases/download/v0.8.0/acs-engine-v0.8.0-linux-amd64.tar.gz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Then, you need to unarchive it:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;tar -xvzf acs-engine-v0.8.0-linux-amd64.tar.gz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This will create a folder called &lt;code&gt;acs-engine-v0.8.0-linux-amd64&lt;/code&gt;, and inside it you will find (among the license and the readme) the &lt;code&gt;acs-engine&lt;/code&gt; binary.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s18-azure/acs-engine-shell.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now you only need to put it in your path (or move it to a directory that is in your path) and you have the &lt;code&gt;acs-engine&lt;/code&gt; binary accessible from anywhere.&lt;/p&gt;

&lt;p&gt;We will now use this binary inside the Azure Cloud Shell to deploy a Kubernetes 1.8 cluster to Azure, using a cluster definition template file.&lt;/p&gt;

&lt;h1 id=&#34;deploy-the-cluster&#34;&gt;Deploy the cluster&lt;/h1&gt;

&lt;p&gt;This is how a typical cluster definition file looks for Kubernetes. Compared to &lt;a href=&#34;https://github.com/Azure/acs-engine/blob/master/examples/kubernetes.json&#34;&gt;the example offered in the repo&lt;/a&gt;, this only adds the &lt;code&gt;orchestratorRelease&lt;/code&gt; property and sets it to &lt;code&gt;1.8&lt;/code&gt;.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/7ba751e0074621313b997c12ccf28dbe.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The great thing about this version of &lt;code&gt;acs-engine&lt;/code&gt; is that you will only need one command to deploy this, and you pass a few parameters (in older versions you would generate ARM templates using &lt;code&gt;acs-engine&lt;/code&gt; and deploy them with the &lt;code&gt;az&lt;/code&gt; command line):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;an Azure subscription id (you can find it using &lt;code&gt;az account show&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;a DNS prefix for your cluster&lt;/li&gt;
&lt;li&gt;the location of your cluster&lt;/li&gt;
&lt;li&gt;the cluster definition file from above&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;acs-engine deploy --subscription-id &amp;lt;your-subscription-id&amp;gt; \
    --dns-prefix &amp;lt;your-dns-prefix&amp;gt; --location westeurope \
    --auto-suffix --api-model kubernetes18.json
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Note the &lt;code&gt;orchestratorRelease&lt;/code&gt; property in the JSON file set to &lt;code&gt;1.8&lt;/code&gt;!
Note that it automatically creates all assets for you including a service principal and a resource group.&lt;/p&gt;

&lt;p&gt;Since you are in the Azure Cloud Shell, you are already authenticated into your Azure account. If you run elswhere, the will be another step involved where you login to &lt;code&gt;aka.ms/devicelogin&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s18-azure/shell.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After the deployment succeeds, you should see a resource group in your subscription with all your Kubernetes assets:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s18-azure/resource-group.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The output of the command above is an &lt;code&gt;_output&lt;/code&gt; folder where you have your SSH keys and the &lt;code&gt;kubeconfig&lt;/code&gt; to access the cluster.&lt;/p&gt;

&lt;p&gt;Now to access the cluster.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Depending on which version of &lt;code&gt;kubectl&lt;/code&gt; you have installed, you might want to &lt;a href=&#34;https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-binary-via-curl&#34;&gt;upgrade to 1.8 as it is detailed here&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now you need to point your &lt;code&gt;kubectl&lt;/code&gt; to the &lt;code&gt;kubeconfig&lt;/code&gt; file location. This has to correspond to the Azure location where you deployed your cluster - in my case West Europe:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;export KUBECONFIG=_output/kubernetes1dot8-59d7ee12/kubeconfig/kubeconfig.westeurope.json&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;At this point you can use &lt;code&gt;kubectl&lt;/code&gt; to get information about your cluster and your nodes:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;kubectl get nodes&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/k8s18-azure/k8s18.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note the &lt;code&gt;v1.8.0&lt;/code&gt;!&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now you have a Kubernetes 1.8 cluster where you can go ahead and use all the awesome features!&lt;/p&gt;

&lt;h1 id=&#34;configure-kubectl-from-outisde-the-azure-cloud-shell&#34;&gt;Configure &lt;code&gt;kubectl&lt;/code&gt; from outisde the Azure Cloud Shell&lt;/h1&gt;

&lt;p&gt;Since we deployed the cluster using the Azure Cloud Shell, all certificates and SSH keys are found in the &lt;code&gt;_output&lt;/code&gt; directory from where you executed the &lt;code&gt;acs-engine deploy&lt;/code&gt; command.
You will want to have access to your cluster from outside the browser (for obvious reasons), so you will have to download the certificates and keys.&lt;/p&gt;

&lt;p&gt;After watching &lt;a href=&#34;https://channel9.msdn.com/Shows/Azure-Friday/Azure-Cloud-Shell&#34;&gt;this video on Channel9 explaining Azure Cloud Shell&lt;/a&gt;, you simply need to put your files in &lt;code&gt;/home/&amp;lt;your-username&amp;gt;/clouddrive&lt;/code&gt;. Then you will find them in the Azure Storage account (more specifically in the the File Share) associated with your Cloud Shell.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you don&amp;rsquo;t want to manually download each file (and you don&amp;rsquo;t have to mount the share), simply make an archive of the entire folder download it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Then, point your local &lt;code&gt;kubectl&lt;/code&gt; to the &lt;code&gt;kubeconfig.&amp;lt;azure-location&amp;gt;.json&lt;/code&gt; file and you have access to your cluster.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that you can also create new users for your cluster, assign them roles and just download the key and certificate for the user, &lt;a href=&#34;https://docs.bitnami.com/kubernetes/how-to/configure-rbac-in-your-kubernetes-cluster/&#34;&gt;as described in the Bitnami documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;conclusion-feedback&#34;&gt;Conclusion, feedback&lt;/h1&gt;

&lt;p&gt;In this brief article we saw how to deploy a Kubernetes 1.8 cluster on Azure using &lt;code&gt;acs-engine&lt;/code&gt; and the Azure Cloud Shell.&lt;/p&gt;

&lt;p&gt;If you have any ideas, comments or feedback, please use the comments below :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The Hybrid Cluster: A CI/CD Story [Part 1] - Configuring a hybrid swarm mode cluster in Azure with acs-engine</title>
      <link>https://radu-matei.com/blog/hybrid-swarmmode/</link>
      <pubDate>Mon, 03 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://radu-matei.com/blog/hybrid-swarmmode/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;This is the first part in our (at least) two parts describing how to get started with a hybrid Docker Swarm Mode cluster. In this first part, we will focus on deploying a hybrid cluster on Azure.&lt;/p&gt;

&lt;p&gt;Now, you can create yourself a hybrid cluster within any private network where you have a Windows Server 2016 with Containers and a Linux machine - it can be locally, with VirtualBox, Hyper-V or VMWare, or it can be on your cloud provider of choice. The simplicity of Docker Swarm allows us to easily create a swarm within minutes of having our VMs deployed.&lt;/p&gt;

&lt;p&gt;Here is a list of resources you might want to get started with before diving into this article:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/swarm/swarm-tutorial/&#34;&gt;Getting started with Swarm Mode and Linux Containers - Docker docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode&#34;&gt;Getting started with Swarm Mode and Windows Containers - Microsoft docs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/manage-containers/swarm-mode#linuxwindows-mixed-os-clusters&#34;&gt;Initializing a Linux+Windows mixed-os cluster - Microsoft docs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;how-is-this-article-different-compared-to-the-docs-above&#34;&gt;How is this article different compared to the docs above?&lt;/h2&gt;

&lt;p&gt;In this article we will focus on deploying the cluster on Azure programatically, using &lt;a href=&#34;https://github.com/Azure/acs-engine&#34;&gt;acs-engine&lt;/a&gt;, a tool that generates &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-overview&#34;&gt;ARM (Azure Resource Manager) templates&lt;/a&gt; for Docker enabled clusters on Microsoft Azure. It will also deploy all resources necessary for our cluster, like load balancers, configure DNS for masters and agents and scale sets for agents and masters. More on this later.&lt;/p&gt;

&lt;p&gt;While you can &lt;a href=&#34;https://github.com/Azure/acs-engine&#34;&gt;find more information about acs-engine on the GitHub repo&lt;/a&gt;, in short, the tool takes a cluster definition file and outputs ARM templates that can be deployed using the &lt;a href=&#34;https://azure.github.io/projects/clis/&#34;&gt;various Azure command-line interfaces&lt;/a&gt; like Azure CLI 2.0 or Azure PowerShell.&lt;/p&gt;

&lt;h2 id=&#34;getting-started-prerequisites&#34;&gt;Getting started - prerequisites&lt;/h2&gt;

&lt;p&gt;This article will continue under the assumption that you have an active Azure subscription. If you don&amp;rsquo;t, there are various ways to get a free subscription, like &lt;a href=&#34;https://www.visualstudio.com/dev-essentials/&#34;&gt;Visual Studio Dev Essentials&lt;/a&gt; (see &lt;a href=&#34;https://github.com/awesome-opening-opportunities/technical-documentation/blob/master/docs/vs-dev-essentials.md&#34;&gt;this link on how to activate your free monthly $25&lt;/a&gt;), or a &lt;a href=&#34;https://azure.microsoft.com/en-us/free/&#34;&gt;free trial&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Before you get started, there is a &lt;a href=&#34;https://channel9.msdn.com/Events/DXPortugal/OSCAMP-Open-Source-Software-powered-by-Bright-Pixel/The-Hybrid-Swarm-Running-Windows-and-Linux-Apps-in-one-Docker-Cluster&#34;&gt;great talk by Docker Developer Advocate and Microsoft MVP Elton Stoneman titled: The Hybrid Swarm: Running Windows and Linux Apps in one Docker Cluster&lt;/a&gt; where he talks about the concepts involved in having a hybrid swarm cluster and that I highly recommend.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;understanding-all-types-of-containers&#34;&gt;Understanding all types of containers&lt;/h2&gt;

&lt;p&gt;First, there are Linux containers. They have been around for a while now (no, Docker did not invent them) and Docker created awesome tooling and integrations.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/journey.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://blogs.msdn.microsoft.com/allthingscontainer/2016/10/14/why-containers/&#34;&gt;Photo credits to Bruno Terkaly, from this article&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Linux containers use the host kernel to run &amp;ldquo;containerized&amp;rdquo; workloads - that is execute the process inside the container using Linux kernel features like cgroups and namespaces. Of course, to run Linux containers you need a Linux kernel - this hasn&amp;rsquo;t changed and will not change any time soon.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/&#34;&gt;When we talk about the Windows ecosystem&lt;/a&gt;, we have Windows Server Containers and Hyper-V Containers.&lt;/p&gt;

&lt;p&gt;Windows Server Containers, much like Linux containers, share the kernel with the host and other containers. &amp;ldquo;These containers do not provide a hostile security boundary and should not be used to isolate untrusted code.&amp;rdquo; (&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/&#34;&gt;source - Microsoft docs&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Hyper-V Containers - &amp;ldquo;expands on the isolation provided by Windows Server Containers by running each container in a highly optimized virtual machine. In this configuration, the kernel of the container host is not shared with other containers on the same host. These containers are designed for hostile multitenant hosting with the same security assurances of a virtual machine. Since these containers do not share the kernel with the host or other containers on the host, they can run kernels with different versions and configurations.&amp;rdquo; (&lt;a href=&#34;https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/&#34;&gt;source - Microsoft docs&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;However, there&amp;rsquo;s a twist: announced at DockerCon 2017, you will be able to run Linux containers on Windows hosts using Hyper-V Isolation&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/win-linux-containers.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://thenewstack.io/finally-linux-containers-really-will-run-windows-linuxkit/&#34;&gt;Image from The New Stack&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is all possible through the new &lt;a href=&#34;https://github.com/linuxkit/linuxkit&#34;&gt;LinuxKit project&lt;/a&gt;, but more on this on a separate article in the future.&lt;/p&gt;

&lt;p&gt;After we deploy our cluster, we will be able to deploy all types of containers described above.&lt;/p&gt;

&lt;h2 id=&#34;the-acs-engine-cluster-definition&#34;&gt;The acs-engine cluster definition&lt;/h2&gt;

&lt;p&gt;As said earlier, we will use a JSON cluster definition file to, well, define our cluster.&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/f610287201e4c08eb2e69eb5ebd02b2f.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;This is a pretty standard cluster definition file for acs-engine, except for the addition of &lt;code&gt;windowspool&lt;/code&gt;, a pool of Windows Server agents in our cluster.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can find &lt;a href=&#34;https://github.com/Azure/acs-engine/blob/master/docs/clusterdefinition.md&#34;&gt;in-depth documentation for the cluster definition on the acs-engine GitHub repo here.&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;From the definition file, we see that we have a Swarm Mode cluster, with 3 Linux masters, 3 Linux agents and 3 Windows Server 2016 agents. Before we can use this definition file, we need to add the required values for &lt;code&gt;dnxPrefix&lt;/code&gt; for the masters, Linux and Windows agents.&lt;/p&gt;

&lt;p&gt;You must also provide a username and public SSH key for the Linux VMs and a username and password for the Windows VMs, and you can change the default number of 3 for the agent and master count.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/acs-swarmmode.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Compared to the image above, there is an additional VM Scale Set with the Windows agents. All VMs are in the same VNET, with the masters on a private subnet. All VMs are fully accessible to each other.&lt;/p&gt;

&lt;h2 id=&#34;deploying-the-cluster-to-azure&#34;&gt;Deploying the cluster to Azure&lt;/h2&gt;

&lt;p&gt;So far we only have a cluster definition (with values for FQDN, usernames and passwords). Before we can actually deploy, we need to generate the ARM templates using acs-engine.&lt;/p&gt;

&lt;p&gt;In order to do this, we will use the &lt;code&gt;acs-engine&lt;/code&gt; tool. After we have the ARM template, we will use the &lt;code&gt;az&lt;/code&gt; CLI to deploy them. You could install these either locally, or within containers, but the easiest way to do it is to use the &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/cloud-shell/overview&#34;&gt;Azure Cloud Shell&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/cloud-shell.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;List of tools and languages supported in the Azure Cloud Shell&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Log into &lt;a href=&#34;https://portal.azure.com&#34;&gt;portal.azure.com&lt;/a&gt; and request a cloud shell. You should see something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/portal-shell.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now we should &lt;a href=&#34;https://github.com/Azure/acs-engine/blob/master/docs/acsengine.md#downloading-and-building-acs-engine&#34;&gt;follow the instructions in the acs-engine documentation&lt;/a&gt; and install acs-engine in the Azure Cloud Shell.&lt;/p&gt;

&lt;p&gt;First, we need to create a new directory called &lt;code&gt;go&lt;/code&gt; and set it as &lt;code&gt;GOPATH&lt;/code&gt;: &lt;code&gt;mkdir go&lt;/code&gt; and &lt;code&gt;export GOPATH=/home/{yourusername}/go&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Then, we need to download the package for acs-engine: &lt;code&gt;go get github.com/Azure/acs-engine&lt;/code&gt;, then navigate to the source of the package and build it: &lt;code&gt;go build&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Then, we add the &lt;code&gt;bin&lt;/code&gt; folder from the &lt;code&gt;go&lt;/code&gt; directory in the path: &lt;code&gt;export PATH=$PATH:/home/{yourusername}/go/bin&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Now you should be able to execute &lt;code&gt;acs-engine&lt;/code&gt; from any directory:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/acs-engine.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s create the ARM templates we will deploy: in a new directory, download the gist with the initial cluster definition (the gist file from above). You can either copy it yourself, or &lt;code&gt;wget&lt;/code&gt; the file:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;wget https://gist.githubusercontent.com/radu-matei/f610287201e4c08eb2e69eb5ebd02b2f/raw/d6a30f867b09d4baa64f78d2499a154096d053e2/swarmmode-hybrid.json&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After you edit the file with your values, generate the ARM templates using &lt;code&gt;acs-engine generate swarmmode-hybrid.json&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/acs-engine-generate.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This will create an &lt;code&gt;_output&lt;/code&gt; directory that will contain the ARM template tht we will use for the deployment.&lt;/p&gt;

&lt;p&gt;First of all, we will create a new resource group: &lt;code&gt;az group create --location westeurope --name your-resourcegroup-name&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that you should choose the region closest to your location.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Then, using the generated files &lt;code&gt;azuredeploy.json&lt;/code&gt; and &lt;code&gt;azuredeploy.parameters.json&lt;/code&gt;, create a new deployment using the &lt;code&gt;az&lt;/code&gt; command-line interface:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;az group deployment create --name hybrid-swarmmode-deployment --resource-group {your-resource-group} --template-file azuredeploy.json  --parameters azuredeploy.parameters.json&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that you can also use a local installation of &lt;code&gt;az&lt;/code&gt;, or in a container, or any method of deploying ARM templates.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After the deployment started, here is how the resource group should look like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/rg.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice the resources created in the resource group:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;3 public IPs for masters, Linux agents and Windows agents&lt;/li&gt;
&lt;li&gt;load balancers for masters, Linux agents and Windows agents&lt;/li&gt;
&lt;li&gt;VM scale sets for the agents and availability sets&lt;/li&gt;
&lt;li&gt;network interfaces and OS disks for the masters&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;connecting-to-the-cluster&#34;&gt;Connecting to the cluster&lt;/h2&gt;

&lt;p&gt;After the deployment succeeds, you are now ready to connect to the master. You will SSH into the masters using the user and SSH key you setup in the cluster definition file. The 3 FQDNs will have the following template:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;{yourfqdnname}.{azurelocation}.cloudapp.azure.com&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Each master can be publicly accessed using the FQDN and one of the ports (2200..220x) (So you will access the first master on 2200, the second master on 2201 and so on.). For example, to SSH into the first master, use the following:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ssh -i path-to-private-key azureuser@{yourfqdn}.{azurelocation}.cloudapp.azure.com -p 2200&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Then, if you list all nodes in the cluster you might first see this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/docker-node-ls.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This means we only see the 3 masters and the 3 Linux agents. This means that even though the Windows nodes were deployed, they did not join the swarm.&lt;/p&gt;

&lt;p&gt;A very quick solution is to reimage the Windows agents. This means restoring them to the initial state and executing all scripts that were executed when initializing the cluster.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A very probable cause of this could be that &lt;a href=&#34;https://github.com/Azure/acs-engine/blob/dd2edf94e182dd9006ddf3fa8f8388b4e5a1eed5/parts/Install-ContainerHost-And-Join-Swarm.ps1&#34;&gt;the script that joins the Windows agents to the cluster&lt;/a&gt; might get executed before the masters actually start.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After reimaging or restarting the VMs, your cluster should look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/node-ls-wc.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now you have a full hybrid Swarm Mode cluster, with some Windows agents, as well as Linux ones:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/node-inspect.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;deploying-services-to-the-cluster&#34;&gt;Deploying services to the cluster&lt;/h2&gt;

&lt;p&gt;From now on, you can treat this cluster as any other Docker Swarm Mode cluster: with the single mention that you cannot run Linux containers on Windows and Windows containers on Linux. This means that when starting services, we need to put some restrictions in place.&lt;/p&gt;

&lt;p&gt;We will deploy a simple Python web application on Linux that will use a Redis data store that we will run on Windows.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/microsoft-dx/docker-lab/tree/master/apps/python-redis&#34;&gt;The Python application can be found here&lt;/a&gt; and is very similar to the &lt;a href=&#34;https://docs.docker.com/compose/gettingstarted/&#34;&gt;Docker Compose one from the Official Docker Docs&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;script src=&#34;//gist.github.com/radu-matei/7543e906e3633075cd32231e46628bf1.js&#34;&gt;&lt;/script&gt;

&lt;p&gt;The most important thing to notice in the stack file is the deployment constraint on the node operating system. As stated earlier, this is very important in the stack file as a Linux service will not run in a Windows host and vice-versa.&lt;/p&gt;

&lt;p&gt;You can see that the &lt;code&gt;redis&lt;/code&gt; service is based on the Windows version of Redis (not something that you would use in production, here just for showcase) and is based on the Nano Server image.&lt;/p&gt;

&lt;p&gt;To deploy this on the master, you need the file above. You can copy it, or &lt;code&gt;wget&lt;/code&gt; it directly: &lt;code&gt;wget https://gist.githubusercontent.com/radu-matei/7543e906e3633075cd32231e46628bf1/raw/f5e06e372c9a5c57f555e8580eee1c1a5ccb635e/hybrid-stack.yml&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Then, you need to &lt;a href=&#34;https://docs.docker.com/engine/reference/commandline/stack_deploy/&#34;&gt;create a new stack deployment&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker stack deploy --compose-file hybrid-stack.yml python-redis&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/stack-deploy.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This will create two new services, the web and Redis ones, and a new network for them.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/service-ls.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://hub.docker.com/r/library/redis/&#34;&gt;Since the Nanoserver Redis image&lt;/a&gt; is around 340 MB, it will take a little to pull it, then start a container.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now since the application that exposes ports is the one running on a Linux node (the web application), we will access it on the port 80 (the one exposed) of the Linux agent FQDN:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/hybrid-swarmmode/running.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article we saw how to deploy a hybrid Swarm Mode cluster on Azure using acs-engine and how to deploy a mixed-OS containerized application on the cluster we created.&lt;/p&gt;

&lt;h2 id=&#34;next-steps&#34;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;Next, we will explore how to create a consistent CI/CD story with GitHub and Jenkins (with Linux and Windows slaves that are created dynamically for each build).&lt;/p&gt;

&lt;h2 id=&#34;feedback&#34;&gt;Feedback&lt;/h2&gt;

&lt;p&gt;If you think this article could be better, please provide your feedback in the comments below.&lt;/p&gt;

&lt;h2 id=&#34;thanks-for-reading&#34;&gt;Thanks for reading :)&lt;/h2&gt;
</description>
    </item>
    
    <item>
      <title>Dockerizing an ASP.NET Core application with GitHub, Docker Cloud and Azure</title>
      <link>https://radu-matei.com/blog/aspnet-core-docker-azure/</link>
      <pubDate>Sat, 26 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://radu-matei.com/blog/aspnet-core-docker-azure/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In this article, we will take the simplest ASP.NET Core application, run it with Docker locally, then create Continuous Integration and Continuous Deployment flows using a GitHub repository, Docker Cloud and an Azure virtual machine that will act as a node for Docker Cloud.&lt;/p&gt;

&lt;p&gt;If you don&amp;rsquo;t want to create an ASP.NET Core application but are interested in the CI/CD workflow, or if you already have a GitHub repository with a complete application with a Dockerfile, &lt;a href=&#34;!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!&#34;&gt;you might want to skip to the part we start creating the CI/CD workflow.&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;moving-parts-and-used-components&#34;&gt;Moving parts and used components&lt;/h2&gt;

&lt;p&gt;The main part of a CI/CD workflow like this is the application itself. It can be however complicated, but in this case I want to emphasize the workflow itself and will only build a very simple application with ASP.NET Core.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that you can use this article with any single-container application you want to build.&lt;/p&gt;

&lt;p&gt;However, if you want to build multi-container applications, you will most likely need a way to compose and orchestrate those containers. In future articles, we will also deal with multi-container applications, but in this one we will keep things easy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We will create a GitHub repository that we will use to create a Docker image and push it to Docker Hub.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker Hub is a cloud-based registry service which allows you to link to code repositories, build your images and test them, stores manually pushed images, and links to Docker Cloud so you can deploy images to your hosts. It provides a centralized resource for container image discovery, distribution and change management, user and team collaboration, and workflow automation throughout the development pipeline.&lt;/p&gt;

&lt;p&gt;More information about Docker Hub on &lt;a href=&#34;https://docs.docker.com/docker-hub/&#34;&gt;the Official Docker Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Then, we will configure an Azure VM to be a node for Docker Cloud and Docker Cloud will automatically publish containers to that VM. Then, every time there are changes in the GitHub repository, Docker Cloud will build the image and publish the container again automatically.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;More information about Docker Cloud on &lt;a href=&#34;https://docs.docker.com/docker-cloud/overview/&#34;&gt;the Official Docker Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/ci-cd-workflow.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.docker.com/2016/04/cicd-with-docker-cloud/&#34;&gt;Photo source on the Docker Blog&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;create-a-github-repository&#34;&gt;Create a GitHub repository&lt;/h2&gt;

&lt;p&gt;First, we need a GitHub repository. If you already have a repo with an application you want to use you can do that. However, I will create a new repo and clone it on my computer.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that you can follow this article regardless of your computer OS. It can be done with Windows, Linux or macOS.&lt;/p&gt;

&lt;p&gt;In creating this article, I used macOS, with Docker for Mac and Visual Studio Code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/github-new-repo.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Since this is a .NET Core application, I chose to add a &lt;code&gt;.gitignore&lt;/code&gt; file that will ignore all .NET specific output files after building the application.&lt;/p&gt;

&lt;p&gt;Create the repository, then clone it somewhere locally on your computer. In my case, I would execute &lt;code&gt;git clone https://github.com/radu-matei/aspnet-core-docker-azure&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;creating-the-asp-net-core-application&#34;&gt;Creating the ASP.NET Core application&lt;/h2&gt;

&lt;p&gt;This will be the part with the least focus in this article, since we have covered building ASP.NET Core applications for a while now and you can find a lot resources on this topic, including some on this site.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For ASP.NET Core tutorials, you can &lt;a href=&#34;https://radu-matei.github.io/categories/aspnet-core/&#34;&gt;take a look at some resources on this blog&lt;/a&gt;, consult the &lt;a href=&#34;https://docs.microsoft.com/en-us/aspnet/core/&#34;&gt;official documentation&lt;/a&gt;, or you can watch this &lt;a href=&#34;https://mva.microsoft.com/en-US/training-courses/introduction-to-aspnet-core-10-16841&#34;&gt;Microsoft Virtual Academy course presented by Scott Hanselman and Maria Naggaga&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Basically, we will create the same application as explained in &lt;a href=&#34;https://radu-matei.github.io/blog/aspnet-core-startup/&#34;&gt;this blog post&lt;/a&gt;, but we will build it against .NET Core 1.0.1 (which is the latest stable version at the moment of writing this article).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;While .NET Core 1.0.1 is the latest version at the moment of writing this article, you can also use other versions, since the Docker images are available on Docker Hub.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the folder that was just created from cloning the repository, execute &lt;code&gt;dotnet new&lt;/code&gt; in order to create a new .NET Core application.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/git-clone-dotnet.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now depending on the .NET Core version you have installed on your machine, &lt;code&gt;project.json&lt;/code&gt; will look slightly different:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;Microsoft.NETCore.App&amp;quot;: {
  &amp;quot;type&amp;quot;: &amp;quot;platform&amp;quot;,
  &amp;quot;version&amp;quot;: &amp;quot;1.0.1&amp;quot;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since &lt;code&gt;1.0.1&lt;/code&gt; is the latest stable version, we will use it as example for this application.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You can use any version available on your machine and as image from Microsoft on Docker Hub.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Add the required Kestrel dependency in &lt;code&gt;project.json&lt;/code&gt;, keeping in mind that the version is &lt;code&gt;1.0.1&lt;/code&gt; and respond to any incoming request with a message and the current date and time of the server:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    public static void Main(string[] args)
        {
            var host = new WebHostBuilder()
                .UseKestrel()
                .Configure(app =&amp;gt; app.Run(context =&amp;gt; 
                {
                    return context.Response.WriteAsync($&amp;quot;Hello, Universe! It is {DateTime.Now}&amp;quot;);
                }))
                .Build();

            host.Run();
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this is the entire ASP.NET Core application we will use for this article.&lt;/p&gt;

&lt;h2 id=&#34;writing-the-dockerfile&#34;&gt;Writing the Dockerfile&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Docker can build images automatically by reading the instructions from a Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build users can create an automated build that executes several command-line instructions in succession.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.docker.com/engine/reference/builder/&#34;&gt;More information on the Dockerfile on the Official Docker Documentation&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Basically, the Dockerfile is like a recipe for building container images. It is a script composed of multiple commands executed succesively to create images based on other images.&lt;/p&gt;

&lt;p&gt;You have two options for writing the Dockerfile: you can write it manually, or you can have VS Code write it for you. If you &lt;a href=&#34;https://code.visualstudio.com/Docs/languages/dockerfile&#34;&gt;install the VS Code Docker extension&lt;/a&gt;, press F1 and search for Docker, you should see something similar to:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/vscode-docker.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this case, we will write the Dockerfile manually, mainly because we want to understand all the things involved.&lt;/p&gt;

&lt;p&gt;Create a new file called &lt;code&gt;Dockerfile&lt;/code&gt; (without extension) to the root of the application (in this case in the same folder as &lt;code&gt;project.json&lt;/code&gt; and &lt;code&gt;Program.cs&lt;/code&gt;) with the following content:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM microsoft/dotnet:1.0.1-sdk-projectjson

COPY . /app
WORKDIR /app

RUN [&amp;quot;dotnet&amp;quot;, &amp;quot;restore&amp;quot;]
RUN [&amp;quot;dotnet&amp;quot;, &amp;quot;build&amp;quot;]

EXPOSE 5000/tcp
ENV ASPNETCORE_URLS http://*:5000

ENTRYPOINT [&amp;quot;dotnet&amp;quot;, &amp;quot;run&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The content of the Dockerfile is pretty self-explanatory:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;it gets a base image that has &lt;code&gt;dotnet&lt;/code&gt; installed, the &lt;code&gt;microsoft/dotnet:1.0.1-sdk-projectjson&lt;/code&gt; image&lt;/li&gt;
&lt;li&gt;it copies the source of the application inside the container, in the &lt;code&gt;/app&lt;/code&gt; folder&lt;/li&gt;
&lt;li&gt;it sets the &lt;code&gt;/app&lt;/code&gt; folder as the working folder where the commands will be executed from&lt;/li&gt;
&lt;li&gt;executes &lt;code&gt;dotnet restore&lt;/code&gt; and &lt;code&gt;dotnet build&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;expoes the 5000 port&lt;/li&gt;
&lt;li&gt;sets the environment variable for ASP .NET Core in the container&lt;/li&gt;
&lt;li&gt;when the container starts it will execute the &lt;code&gt;dotnet run&lt;/code&gt; command&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;In this case, we both build and run the application inside the container. In a production environment, we would only use the &lt;code&gt;dotnet runtime&lt;/code&gt; image from Microsoft that is only able to execute applications and not build them. This would result in a much smaller footprint of the image.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;building-the-image&#34;&gt;Building the image&lt;/h2&gt;

&lt;p&gt;At this point, we have configured the application (which wasn&amp;rsquo;t that hard), we have a definition for Docker, our Dockerfile, but we haven&amp;rsquo;t built an image or a container so far.&lt;/p&gt;

&lt;p&gt;The end result is for us to start a container. Every container is built upon an image, that is composed of the application itself and its dependencies.&lt;/p&gt;

&lt;p&gt;To build the image, simply run the following command in the same folder with the Dockerfile:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker build -t aspnet-core-docker-azure&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-build-1.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-build-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can clearly see how each step in the Dockerfile is executed succesively and how at every step an intermediate container gets created. This is done so that if the execution fails at let&amp;rsquo;s say STEP 7, all progress made up to that point doesn&amp;rsquo;t get lost. After every successful step executed, the previous container is removed.&lt;/p&gt;

&lt;p&gt;Running &lt;code&gt;docker images&lt;/code&gt; should show you the newly created image containing your application and its dependencies (among other images that you might have).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-images.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice though that the base for our image also got pulled from Docker Hub - &lt;code&gt;microsoft/dotnet:1.0.1-sdk-projectjson&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;running-a-new-container&#34;&gt;Running a new container&lt;/h2&gt;

&lt;p&gt;Now that we built our image it&amp;rsquo;s time to run a new container based on that image.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker run -d -p 8080:5000 -t aspnet-core-docker-azure&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s examine the aruments passed along the &lt;code&gt;docker run&lt;/code&gt; command:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;-d&lt;/code&gt; - the container will run in &lt;code&gt;detached&lt;/code&gt; mode, so we won&amp;rsquo;t see logs from the container as output&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;-p 8080:5000&lt;/code&gt; - this will map the 5000 port inside the container (that the application is running on&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;remember the Dockerfile) to port 8080 from the host&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;-t&lt;/code&gt; - the tag of the image this container is based on&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This command started our container, so Docker must have executed &lt;code&gt;dotnet run&lt;/code&gt; inside the container (remember the last line in the Dockerfile), so the application should have started.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-run.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The output of this command is the id of the newly created container, so we can verify that the container is running using the &lt;code&gt;docker ps&lt;/code&gt; command:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-ps.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We can see the id of the container, the image it is based on, the command used as entrypoint and the port mapping: 8080 on the host to 5000 inside the container.&lt;/p&gt;

&lt;p&gt;So if we navigate to &lt;code&gt;http://localhost:8080&lt;/code&gt; we should see our application running:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-run-browser.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So far we created a very simple ASP .NET Core application and we ran it locally inside Docker.We  haven&amp;rsquo;t used the GitHub repo, Docker Hub, Docker Cloud or Azure just yet. This is where we start doing so.&lt;/p&gt;

&lt;h2 id=&#34;setup-an-azure-vm-as-node-for-docker-cloud&#34;&gt;Setup an Azure VM as node for Docker Cloud&lt;/h2&gt;

&lt;p&gt;While Docker Cloud allows you to run containers and build images on some free tier servers, you would most likely want to do it on your own machine.&lt;/p&gt;

&lt;p&gt;If you link the Docker Cloud account with your cloud subscription (in this case Azure), you can create nodes and clusters directly from the Docker Cloud portal.&lt;/p&gt;

&lt;p&gt;In this case we will normally create a VM from the Azure Portal (or from any other cloud provider or on-premise) and install the Docker Cloud agent.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-cloud-bring-node.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I created an Ubuntu Server 14.04 VM (at the moment of writing this article, only Ubuntu 14.04 and 15.04 are supported by Docker Cloud).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/azure-create-vm-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After the deployment succeeds, we will need to open some ports on that VM so the Docker Cloud self discovery service can work. &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/virtual-machines/virtual-machines-windows-nsg-quickstart-portal&#34;&gt;In this article you can see the detalied process on how to open ports for Azure VMs.&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;We recommend you open incoming port 2375 in your firewall for Docker Cloud to communicate with the Docker daemon running in the node. For the overlay network to work, you must open port 6783/tcp and 6783/udp.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You have to find the &lt;code&gt;Network Security Group&lt;/code&gt; tab from the VM settings, then the &lt;code&gt;Network Security Group&lt;/code&gt; tab then the &lt;code&gt;Inbound Security Roules&lt;/code&gt; tab.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/azure-network-security.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As the Docker Cloud documentation states, we should open ports 2375 and 6783/tcp and udp.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-2375.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Then do the same for 6783/tcp and 6783/udp, and since this VM will host the running container, I will also open a port for HTTP - which will automatically open port 80.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you plan to run multiple containers at the same time that expose ports on this machine, you should open more ports to be accessible from outside the VM.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I will also setup a DNS name for the VM so that I don&amp;rsquo;t have to remember the IP of the machine:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/azure-vm-dns.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At this point, you should be able to SSH into the machine and install the Docker Cloud agent.&lt;/p&gt;

&lt;p&gt;On macOS, Linux or Bash on Windows, to SSH into a machine:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ssh user-name@your-machine-dns-or-ip&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;In my case, I would run
 &lt;code&gt;ssh radu-matei@ubuntu-docker-cloud.westeurope.cloudapp.azure.com&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/azure-vm-ssh.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After this, I could just paste the command that installs the Docker Cloud agent:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;curl -Ls https://get.cloud.docker.com/ | sudo -H sh -s your-unique-hash&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;You might still see some Tutum references in the scripts, as this was the name of the company acquired by Docker that initially developed the functionality behind Docker Cloud.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After the command above successfully executed and you refreshed your Docker Cloud tab, you should see your newly created node.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-node.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is all the required setup for a VM to be a Docker Cloud node.&lt;/p&gt;

&lt;h2 id=&#34;creating-a-repository-in-docker-cloud&#34;&gt;Creating a repository in Docker Cloud&lt;/h2&gt;

&lt;p&gt;By now, the GitHub repository with the application should be up to date, since we will use it to create a new Docker Cloud repository that will automatically build images on every git push in the GitHub repo.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-create-repo.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;By default, the webhook will be setup for the master branch on every push, but you can also set it up for specific events, like certain releases.&lt;/p&gt;

&lt;p&gt;By default, the newly created image will be public, but you can make it private. Note that you have a limited number of private repositories in the free tier.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-repo-info.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After it was created and Docker Cloud successfully tested the connection with GitHub, we should set the build process so that it uses the node we just provided and not the shared one provided by Docker Cloud:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/docker-repo-build.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you configured automated notifications on Slack, every time there is an event related to the service you are creating, you will have notifications on Slack.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/slack-notifications.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After you click &lt;code&gt;Save and Build&lt;/code&gt; the image building will start on the machine you provided.&lt;/p&gt;

&lt;p&gt;At any time you can see the logs from building the image in the &lt;code&gt;Builds&lt;/code&gt; tab.
&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/build-logs.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now if you go to Docker Hub you should see your newly created image.&lt;/p&gt;

&lt;h2 id=&#34;creating-a-service-based-on-the-image-we-created&#34;&gt;Creating a service based on the image we created&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;A service is a group of containers of the same image:tag. Services make it simple to scale your application. With Docker Cloud, you simply drag a slider to change the number of containers in a service.&lt;/p&gt;

&lt;p&gt;Before you can deploy a service in Docker Cloud, you must have at least one node deployed. If you haven’t done this yet follow the tutorial to deploy a node .&lt;/p&gt;

&lt;p&gt;When you create a service in the Docker Cloud web interface, a wizard walks you through configuring the service in three steps.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Choose a Container Image Images can come from Docker Cloud’s Jumpstarts library, your personal Docker Hub account or Docker Hub’s public index, or from third party registries you connect.&lt;/li&gt;
&lt;li&gt;Configure the Service From here, give the service a name, set the initial number of containers, expose/publish ports, modify the run command or entrypoint, set memory and CPU limits.&lt;/li&gt;
&lt;li&gt;Set Environment variables Set the edit environment variables and link your service to other existing services in Docker Cloud.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;More on Docker Cloud services on &lt;a href=&#34;https://docs.docker.com/docker-cloud/getting-started/your_first_service/&#34;&gt;the Official Docker Documentation&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We will create a service based on the image we just created.&lt;/p&gt;

&lt;p&gt;The only custom settings will be to enable the &lt;code&gt;AUTOREDEPLOY&lt;/code&gt; option and to specify the port to be 80 on the machine.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/autoredeploy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/port.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After hitting the create, it will create the service and already start a container based on this service.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/service-starting.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;If we go to the containers tab, we can see the container running.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/containers.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;testing-the-application&#34;&gt;Testing the application&lt;/h2&gt;

&lt;p&gt;Remember the DNS we assigned to the Azure VM? In my case it was &lt;code&gt;http://ubuntu-docker-cloud.westeurope.cloudapp.azure.com/&lt;/code&gt;. Normally, the container should have started on port 80 (the default HTTP port) on this machine.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s try and access that exact URL:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/public-app.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At this point, you can create additional service and start containers on this machine, provided you open ports on the VM with the procedure described above.&lt;/p&gt;

&lt;h2 id=&#34;updating-the-application&#34;&gt;Updating the application&lt;/h2&gt;

&lt;p&gt;Because we setup the image based on the GitHub repository and we checked the &lt;code&gt;AUTOREDEPLOY&lt;/code&gt; option, every time we will push on the master branch of the repository, the entire system will update itself.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s slightly modify the application and push the modifications. This should trigger the auto build and auto redeploy of the container and without us doing anything, the modifications should be live.&lt;/p&gt;

&lt;p&gt;I just changed the message the application responds with and pushed the modifications to the master branch. This should trigger the build and redeploy of the container.&lt;/p&gt;

&lt;p&gt;You should see the new build in the &lt;code&gt;Recent Builds&lt;/code&gt; tab from the &lt;code&gt;Repositories&lt;/code&gt; page:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/recent-builds.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can also see all events in Slack:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/slack-build-events.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;After the build and redeploy are successful, accessing the application should reflect the modifications:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://radu-matei.com/img/article-photos/aspnet-core-docker-azure/public-app-updated.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This is basically how the entire process looks like. It is not production ready, as it does not have any testing workflow put in place and the application is rather simple.&lt;/p&gt;

&lt;p&gt;Real world scenarions would most certainly involve more containers, so composing and orchestrating containers, as well as testing.&lt;/p&gt;

&lt;p&gt;We will try to deal with these aspects in future articles, but for now we created a very simple CI/CD workflow using GitHub, Docker Cloud and an Azure VM.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ASP.NET Core MVC and SignalR Core</title>
      <link>https://radu-matei.com/blog/aspnet-core-mvc-signalr/</link>
      <pubDate>Fri, 09 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://radu-matei.com/blog/aspnet-core-mvc-signalr/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In this article we will take a look at how to integrate ASP.NET Core MVC with SignalR Core (at the moment of writing this article, the latest version of SignalR is &lt;a href=&#34;https://dotnet.myget.org/feed/aspnetcore-ci-dev/package/nuget/Microsoft.AspNetCore.SignalR.Server&#34;&gt;&lt;code&gt;0.2.0-alpha1-22107&lt;/code&gt;&lt;/a&gt;) and how to use the SignalR context outside hubs (and solve the current issues with the custom resolvers that will be detailed later) to update clients.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This article assumes a basic understanding of ASP.NET Core MVC and will not try to explain all concepts here. &lt;a href=&#34;https://radu-matei.github.io/blog/aspnet-core-api/&#34;&gt;This article&lt;/a&gt; does an introduction to ASP.NET Core MVC and has the basic application structure needed for this article.&lt;/p&gt;

&lt;p&gt;In order to get started with SignalR Core, &lt;a href=&#34;https://radu-matei.github.io/blog/signalr-core/&#34;&gt;take a look at this article&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We will build on &lt;a href=&#34;https://radu-matei.github.io/blog/aspnet-core-api/&#34;&gt;this application&lt;/a&gt; and add real time functionality to it.&lt;/p&gt;

&lt;p&gt;It is a very simple application that will enable the creation of posts (much like messages) and it took us through adding the MVC services, creating models, controllers and consuming some data. Now, we want all connected users to see in real time when somebody adds posts in the page without refreshing it.&lt;/p&gt;

&lt;h2 id=&#34;configure-the-application&#34;&gt;Configure the application&lt;/h2&gt;

&lt;p&gt;NuGet has the ability to get packages from more than one source, and we need it to download alpha packages that are only available on the MyGet server of the ASP.NET team, besides the ASP.NET Core packages available on NuGet. So in the root of the application add a file called &lt;code&gt;NuGet.Config&lt;/code&gt; with the following content:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;utf-8&amp;quot;?&amp;gt;
&amp;lt;configuration&amp;gt;
    &amp;lt;packageSources&amp;gt;
        &amp;lt;clear/&amp;gt;
            &amp;lt;add key=&amp;quot;aspnetcidev&amp;quot; value=&amp;quot;https://dotnet.myget.org/F/aspnetcore-ci-dev/api/v3/index.json&amp;quot;/&amp;gt;
            &amp;lt;add key=&amp;quot;api.nuget.org&amp;quot; value=&amp;quot;https://api.nuget.org/v3/index.json&amp;quot;/&amp;gt;
    &amp;lt;/packageSources&amp;gt;
&amp;lt;/configuration&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;add-the-required-packages&#34;&gt;Add the required packages&lt;/h2&gt;

&lt;p&gt;For this application, we will need the Kestrel web server (of course), the MVC packages so we can use controllers, static files so we can have HTML and JavaScript files served, SignalR and WebSockets:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;Microsoft.AspNetCore.Server.Kestrel&amp;quot;: &amp;quot;1.0.0&amp;quot;,
&amp;quot;Microsoft.AspNetCore.Mvc&amp;quot;: &amp;quot;1.0.0&amp;quot;,
&amp;quot;Microsoft.AspNetCore.StaticFiles&amp;quot;: &amp;quot;1.0.0&amp;quot;,
&amp;quot;Microsoft.AspNetCore.SignalR.Server&amp;quot;: &amp;quot;0.2.0-*&amp;quot;,
&amp;quot;Microsoft.AspNetCore.WebSockets&amp;quot;: &amp;quot;0.2.0-*&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;program-cs&#34;&gt;&lt;code&gt;Program.cs&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Besides adding the &lt;code&gt;UseContentRoot&lt;/code&gt; statement, the &lt;code&gt;Main&lt;/code&gt; method is pretty much standard for an ASP.NET Core application.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; public static void Main(string[] args)
 {
     var host = new WebHostBuilder()
         .UseKestrel()
         .UseContentRoot(Directory.GetCurrentDirectory())
         .UseStartup&amp;lt;Startup&amp;gt;()
         .Build();

     host.Run();
 }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;post-ipostrepository-and-postrepository&#34;&gt;&lt;code&gt;Post&lt;/code&gt;, &lt;code&gt;IPostRepository&lt;/code&gt; and &lt;code&gt;PostRepository&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://radu-matei.github.io/blog/aspnet-core-api/&#34;&gt;This article&lt;/a&gt; explains all these components thoroughly, but let&amp;rsquo;s see briefly what each one does:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Post
{
    public int Id { get; set; }
    public string UserName { get; set; }
    public string Text { get; set; }

    public Post(int id, string userName, string text)
    {
        Id = id;
        UserName = userName;
        Text = text;
    }

    public Post()
    {
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;Post&lt;/code&gt; will be the model that users add in the application. It is a straightforward C# class with three auto-implemented properties and two constructors.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Each user that enters can publish a post containing his user name and a text, so our Post class only contains two properties for the UserName and Text of the post and an Id.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;using System.Collections.Generic;

public interface IPostRepository
{
    List&amp;lt;Post&amp;gt; GetAll();
    Post GetPost(int id);
    void AddPost(Post post);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Regardless of where that data is going to be stored, there should be a consistent way of reading and writing, and we will achieve this through an interface, IPostRepository, that will expose the minimum necessary methods: a method to read all posts, a method to add a post and a method to retrieve a post with a specified id.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code&gt;using System.Collections.Generic;
using System.Linq;

public class PostRepository : IPostRepository
{
    private List&amp;lt;Post&amp;gt; _posts = new List&amp;lt;Post&amp;gt;()
    {
        new Post(1, &amp;quot;Obi-Wan Kenobi&amp;quot;,&amp;quot;These are not the droids you&#39;re looking for&amp;quot;),
        new Post(2, &amp;quot;Darth Vader&amp;quot;,&amp;quot;I find your lack of faith disturbing&amp;quot;)
    };
    public void AddPost(Post post)
    {
        _posts.Add(post);
    }

    public List&amp;lt;Post&amp;gt; GetAll()
    {
        return _posts;
    }

    public Post GetPost(int id)
    {
        return _posts.FirstOrDefault(p =&amp;gt; p.Id == id);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;We implemented the &lt;code&gt;IPostRepository&lt;/code&gt; interface through an in-memory class called &lt;code&gt;PostRepository&lt;/code&gt; that holds the data in a list. Since we have the three methods to access the data, there is no need to expose the post list outside the class, so it is be private. Besides the list, we only need to implement the three methods from the interface.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;the-postscontroller&#34;&gt;The &lt;code&gt;PostsController&lt;/code&gt;&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;using System.Collections.Generic;
using Microsoft.AspNetCore.Mvc;
using Microsoft.AspNetCore.SignalR.Infrastructure;

public class PostsController : Controller
{
    private IPostRepository _postRepository { get; set; }

    public PostsController(IPostRepository postRepository)
    {
        _postRepository = postRepository;
    }

    [HttpGet]
    public List&amp;lt;Post&amp;gt; GetPosts()
    {
        return _postRepository.GetAll();
    }

    [HttpGet]
    public Post GetPost(int id)
    {
        return _postRepository.GetPost(id);
    }

    [HttpPost]
    public void AddPost(Post post)
    {
        _postRepository.AddPost(post);
    }
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;From this controller, we will update all clients when a post was added using SignalR by getting the context of the hub and calling client methods  using a &lt;code&gt;ConnectionManager&lt;/code&gt;. We will see later how to achieve this.&lt;/p&gt;

&lt;h2 id=&#34;add-a-hub&#34;&gt;Add a hub&lt;/h2&gt;

&lt;p&gt;In this application, we will use the hub as a proxy: clients will not call hub methods directly. SignalR will be used to provide server updates - that is the server notifies all clients that something happened, so the clients must first connect to a hub.&lt;/p&gt;

&lt;p&gt;So the hub class will be incredibly simple:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using Microsoft.AspNetCore.SignalR;

public class PostsHub : Hub
{
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We will see how to use the hub context outside of the hub a little later.&lt;/p&gt;

&lt;h2 id=&#34;camel-case-issues-and-custom-contract-resolvers&#34;&gt;Camel case issues and custom contract resolvers&lt;/h2&gt;

&lt;p&gt;At this moment, MVC uses camel case notation to pass JSON to clients. That means that even if on the server you write your class properties with Pascal case notation (as you should!), JavaScript clients would get Camel cased objects.&lt;/p&gt;

&lt;p&gt;This behavior is new to ASP.NET Core and was not present in the older versions when SignalR was used and built, so SignalR and its clients all expect Pascal case objects, while the objects passed between MVC and its clients are camel cased. This means we cannot reuse metods across the JavaScript client, thing we cannot tolerate.&lt;/p&gt;

&lt;p&gt;So we are going to make SignalR pass objects in camel case. Basically, we are going to &amp;ldquo;recycle&amp;rdquo; &lt;a href=&#34;https://github.com/SignalR/SignalR/issues/500#issuecomment-7453751&#34;&gt;this old SignalR GitHub issue&lt;/a&gt; and adapt it to our versions of ASP.NET and SignalR.&lt;/p&gt;

&lt;h2 id=&#34;add-a-custom-contract-resolvers&#34;&gt;Add a custom contract resolvers&lt;/h2&gt;

&lt;p&gt;A first try could be to change the default contract resolver to a &lt;code&gt;CamelCasePropertyNamesContractResolver()&lt;/code&gt; inside the &lt;code&gt;ConfigureServices&lt;/code&gt; method:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var settings = new JsonSerializerSettings();
settings.ContractResolver = new CamelCasePropertyNamesContractResolver();

var serializer = JsonSerializer.Create(settings);
services.Add(new ServiceDescriptor(typeof(JsonSerializer), 
             provider =&amp;gt; serializer, 
             ServiceLifetime.Transient));

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While this is not far from what we are going to do, at this moment we simply cannot force all components to pass camel case objects because it would break current conventions in place.&lt;/p&gt;

&lt;p&gt;Simply put, if you try this the JavaScript client will no longer connect, because all connection and internal communication is tansformed to camel case.&lt;/p&gt;

&lt;p&gt;We are at the point where we need all of the application objects to be passed camel cased, and all connection and SignalR internal objects to be unmodified.&lt;/p&gt;

&lt;p&gt;We will write a custom contract resolver that looks at the assembly of the object type and if it is not an internal SignalR object (if it is not from the same assembly as &lt;code&gt;Connection&lt;/code&gt;, a class from SignalR), then it modifies it to be camel case:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;using System;
using System.Reflection;
using Microsoft.AspNetCore.SignalR.Infrastructure;
using Newtonsoft.Json.Serialization;

    public class SignalRContractResolver : IContractResolver
    {
        private readonly Assembly _assembly;
        private readonly IContractResolver _camelCaseContractResolver;
        private readonly IContractResolver _defaultContractSerializer;

        public SignalRContractResolver()
        {
            _defaultContractSerializer = new DefaultContractResolver();
            _camelCaseContractResolver = new CamelCasePropertyNamesContractResolver();
            _assembly = typeof(Connection).GetTypeInfo().Assembly;
        }


        public JsonContract ResolveContract(Type type)
        {
            if (type.GetTypeInfo().Assembly.Equals(_assembly))
                return _defaultContractSerializer.ResolveContract(type);

            return _camelCaseContractResolver.ResolveContract(type);
        }

    }

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So in &lt;code&gt;ConfigureServices&lt;/code&gt; we register our contract resolver very similarly to what we had earlier:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var settings = new JsonSerializerSettings();
settings.ContractResolver = new SignalRContractResolver();

var serializer = JsonSerializer.Create(settings);
services.Add(new ServiceDescriptor(typeof(JsonSerializer), 
             provider =&amp;gt; serializer, 
             ServiceLifetime.Transient));
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that most likely, this will be done more elegantly in future releases.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;the-configure-method&#34;&gt;The &lt;code&gt;Configure&lt;/code&gt; method&lt;/h2&gt;

&lt;p&gt;Again, the &lt;code&gt;Configure&lt;/code&gt; method is pretty straightforward: we add static files support, configure MVC and add WebSockets and SignalR.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    public void Configure(IApplicationBuilder app)
    {
        app.UseStaticFiles();

        app.UseMvc(routes =&amp;gt; 
        {
            routes.MapRoute(
                    name: &amp;quot;default&amp;quot;,
                    template: &amp;quot;api/{controller}/{action}/{id?}&amp;quot;
            );
        });

        app.UseWebSockets();
        app.UseSignalR();
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;calling-client-methods-outside-hubs&#34;&gt;Calling client methods outside hubs&lt;/h2&gt;

&lt;p&gt;In the previous versions of SignalR, in order to call client methods and manage groups outside a hub you would need to make use of the &lt;code&gt;GlobalHost&lt;/code&gt;, which is no longer available in the new version.&lt;/p&gt;

&lt;p&gt;So we will use an instance of &lt;code&gt;ConnectionManager&lt;/code&gt;, specifically the &lt;code&gt;GetHubContext&amp;lt;&amp;gt;()&lt;/code&gt; method. We need to register this service so we can use it in the controller:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;_connectionManager.GetHubContext&amp;lt;PostsHub&amp;gt;().someClientMethod(parameters)&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-configureservices-method&#34;&gt;The &lt;code&gt;ConfigureServices&lt;/code&gt; method&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;    public void ConfigureServices(IServiceCollection services)
    {
        var settings = new JsonSerializerSettings();
        settings.ContractResolver = new SignalRContractResolver();

        var serializer = JsonSerializer.Create(settings);

        services.Add(new ServiceDescriptor(typeof(JsonSerializer), 
                     provider =&amp;gt; serializer, 
                     ServiceLifetime.Transient));

        services.AddSingleton&amp;lt;IPostRepository, PostRepository&amp;gt;();

        services.AddSignalR(options =&amp;gt; 
        {
            options.Hubs.EnableDetailedErrors = true;
        });
        
        services.AddMvc();
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We added the new contract resolver, we added the &lt;code&gt;PostRepository&lt;/code&gt; and we added SignalR. Now we need to use it in the controller:&lt;/p&gt;

&lt;h2 id=&#34;the-updated-controller&#34;&gt;The updated controller&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;using System.Collections.Generic;
using Microsoft.AspNetCore.Mvc;
using Microsoft.AspNetCore.SignalR.Infrastructure;

public class PostsController : Controller
{
    private IPostRepository _postRepository { get; set; }
    private IConnectionManager _connectionManager {get; set; }

    public PostsController(IPostRepository postRepository, IConnectionManager connectionManager)
    {
        _postRepository = postRepository;
        _connectionManager = connectionManager;
    }

    [HttpGet]
    public List&amp;lt;Post&amp;gt; GetPosts()
    {
        return _postRepository.GetAll();
    }

    [HttpGet]
    public Post GetPost(int id)
    {
        return _postRepository.GetPost(id);
    }

    [HttpPost]
    public void AddPost(Post post)
    {
        _postRepository.AddPost(post);
        _connectionManager.GetHubContext&amp;lt;PostsHub&amp;gt;().Clients.All.publishPost(post);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Every time someone adds a new post, all connected users will be notified and will call the &lt;code&gt;publishPost&lt;/code&gt; method.&lt;/p&gt;

&lt;h2 id=&#34;the-client&#34;&gt;The client&lt;/h2&gt;

&lt;p&gt;The client will be exactly the same as in SignalR 2.2.x:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
    &amp;lt;title&amp;gt;&amp;lt;/title&amp;gt;
	&amp;lt;meta charset=&amp;quot;utf-8&amp;quot; /&amp;gt;

    &amp;lt;script src=&amp;quot;http://ajax.aspnetcdn.com/ajax/jQuery/jquery-2.2.0.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script src=&amp;quot;http://ajax.aspnetcdn.com/ajax/signalr/jquery.signalr-2.2.0.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;script src=&amp;quot;/signalr/hubs&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    
    &amp;lt;input id=&amp;quot;userNameInput&amp;quot; type=&amp;quot;text&amp;quot; placeholder=&amp;quot;Enter your user name...&amp;quot; /&amp;gt;
    &amp;lt;input id=&amp;quot;textInput&amp;quot; type=&amp;quot;text&amp;quot; placeholder=&amp;quot;Enter your status...&amp;quot; /&amp;gt;

    &amp;lt;button id=&amp;quot;publishPostButton&amp;quot;&amp;gt;Publish post!&amp;lt;/button&amp;gt;

    &amp;lt;ul id=&amp;quot;postsList&amp;quot;&amp;gt;&amp;lt;/ul&amp;gt;
    
    &amp;lt;script type=&amp;quot;text/javascript&amp;quot;&amp;gt;
        $.ajax({
            url: &#39;/api/Posts/GetPosts&#39;,
            method: &#39;GET&#39;,
            dataType: &#39;JSON&#39;,
            success: addPostsList
        });

        function addPostsList(posts) {
            $.each(posts, function (index) {
                var post = posts[index];
                addPost(post);
            });
        }

        function addPost(post) {
            $(&amp;quot;#postsList&amp;quot;).append(
                    &#39;&amp;lt;li&amp;gt;&amp;lt;b&amp;gt;&#39; + post.userName + &#39;&amp;lt;/b&amp;gt;&amp;lt;br&amp;gt;&#39; + post.text + &#39;&amp;lt;/li&amp;gt;&amp;lt;br&amp;gt;&#39;
                 );
        }

        var hub = $.connection.postsHub;

        hub.client.publishPost = addPost;

        $(&amp;quot;#publishPostButton&amp;quot;).click(function () {

            var post = {
                userName: $(&amp;quot;#userNameInput&amp;quot;).val() || &amp;quot;Guest&amp;quot;,
                text: $(&amp;quot;#textInput&amp;quot;).val()
            };
            $.ajax({
                url: &#39;/api/Posts/AddPost&#39;,
                method: &#39;POST&#39;,
                data: post
            });
        });
        
        $.connection.hub.logging = true;
        $.connection.hub.start();
    &amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now if you open two browser tabs and start adding messages, you can see all pages updating in real time.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article we saw how to use MVC Core and SignalR for providing real time data to users.&lt;/p&gt;

&lt;p&gt;Since SignalR is still in alpha, at this moment there are some issues to be addressed and many breaking changes to come and I will try to keep this example up-to-date.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>